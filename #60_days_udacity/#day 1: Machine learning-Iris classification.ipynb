{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr81q-KmosqU",
        "colab_type": "text"
      },
      "source": [
        "# Machine learning-Iris classification\n",
        "Welcome to the first day of <font color = \"blue\">#60daysofcode</font> proposed by Udacity.I decided to put what I learnt from this Nanodegree in practice so I started by lesson 3 and exactly **classification** problem so today I'm  going to develop the model that is going to **classify** the **iris** flowers for us.\n",
        "\n",
        "The data used here is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica.\n",
        "\n",
        "Let’s try to create the model that can classify the different species of the Iris flower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVDdna-XrIo8",
        "colab_type": "text"
      },
      "source": [
        "**Problem solving:**\n",
        "\n",
        "*   create the dataset.\n",
        "*   Exploring the data\n",
        "*   Build the model\n",
        "*   Train the model\n",
        "*   Make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8k9nGcOrXtK",
        "colab_type": "text"
      },
      "source": [
        "**1.Create the datasets:**\n",
        "In order to classify the different species of the Iris,We should prepare the datasets with **features** and **labels**.But sklearn comes with the inbuilt datasets for the iris classification problem, so no need to worry :) .\n",
        "\n",
        "Let us first understand the datasets\n",
        "\n",
        "The data set consists of:\n",
        "\n",
        "*   150 samples\n",
        "*   3 labels: species of Iris (Iris setosa, Iris virginica and Iris versicolor)\n",
        "*   4 features: Sepal length,Sepal width,Petal length,Petal Width in cm\n",
        "\n",
        "You need to note that Scikit learn only works if data is stored as numeric data, irrespective of it being a **regression** or a **classification** problem. It also requires the arrays to be stored at **numpy arrays** for optimization. \n",
        "\n",
        "Since, this dataset is loaded from scikit learn, everything is appropriately formatted.\n",
        "\n",
        "Let's jump to the first line of code and undrestand it all :) :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aYbfVxdsOvq",
        "colab_type": "text"
      },
      "source": [
        "First of all we need to load the Iris dataset for that we will import our data from sklearn library and we will need to use numpy for after.\n",
        "\n",
        "Second step is to make a variable named \"iris\" (just to make it simple for us to undrestand but you can call it by your name don't worry :) ) and use <font color=\"blue\"> datasets.load_iris() </font> that's load and return the iris dataset (classification)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk2WPLpod-TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from  sklearn import  datasets\n",
        "import numpy as np\n",
        "iris=datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba2cjJFrtxwp",
        "colab_type": "text"
      },
      "source": [
        "**Machine learning terminology:**\n",
        "* Each row is an **observation** (also known as: sample, example, instance, record)\n",
        "* Each column is a **feature** (also known as: predictor, attribute, independent variable, input, regressor, covariate)\n",
        "\n",
        "**2.Exploring the iris dataset:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z53n5sPQuvIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13b7e094-8184-4f05-bb74-c9d14f35271c"
      },
      "source": [
        "# print the names of the four features\n",
        "print (iris.feature_names)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPxseG0jvGIT",
        "colab_type": "text"
      },
      "source": [
        "* Each value we are predicting is the response (also known as: target, outcome, label, dependent variable)\n",
        "* **Classification** is supervised learning in which the response is categorical\n",
        "  * \"0\": setosa\n",
        "  * \"1\": versicolor\n",
        "  * \"2\": virginica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srl6efNqu6DU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "927882e6-1c86-4364-a0cd-92f4751ffe38"
      },
      "source": [
        "# print integers representing the species of each observation\n",
        "# 0, 1, and 2 represent different species\n",
        "print (iris.target)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZkNniMzve_x",
        "colab_type": "text"
      },
      "source": [
        "Assign the data and target to separate variables.\n",
        "* x contains the features.\n",
        "* y contains the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSH5QlDCgDq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=iris.data\n",
        "y=iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky6Bs380mL-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ac33817-15fc-4cc0-9762-8b7e02cc8598"
      },
      "source": [
        "list(iris.keys())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49U-h6ILvykI",
        "colab_type": "text"
      },
      "source": [
        "**Splitting the dataset:**  \n",
        "Since our process involve **training** and **testing** ,We should split our dataset.It can be executed by the following code : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drzI1fH0n8YH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N43JeZfAv6SC",
        "colab_type": "text"
      },
      "source": [
        "The first line: from sklearn.model_selection import train_test_split (what? what That mean??) that's mean From Sklearn, sub-library model_selection, I’ve imported the train_test_split so I can, well, split to training and test sets   \n",
        "**Note that :**\n",
        "* <font color =\"blue\">x_train</font> contains the <font color =\"blue\">training features</font>\n",
        "* <font color =\"green\">x_test</font> contains the <font color =\"green\">testing features</font>\n",
        "* <font color =\"blue\">y_train</font> contains the <font color =\"blue\">training label</font>\n",
        "* <font color =\"green\">y_test</font> contains the <font color =\"green\">testing labels</font>\n",
        "\n",
        "And you use train_test_split(x,y,test_size=.5) to indicate:  \n",
        "* **x:**  iris.data (seen above)  \n",
        "* **y:**  iris.target (seen above)  \n",
        "* **test_size:** float, int or None, optional (default=None)  \n",
        "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.\n",
        "\n",
        "You didn't undrestand this part well? don't worry you can have a look at this exemple and try to implement it [Understanding the data splitting functions in scikit-learn](https://medium.com/@julie.yin/understanding-the-data-splitting-functions-in-scikit-learn-9ae4046fbd26)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw7-weg2wtFG",
        "colab_type": "text"
      },
      "source": [
        "**3.Build the model**  \n",
        "We can use any classification algorithm to solve the problem.In this exemple I will use Logistic Regression because I saw it in the course ;) \n",
        "\n",
        "This code will create the empty model. In order to provide the operations to the model we should train them.  \n",
        "**(Should I use just this model?)** Of course no you can use the model you want and even try different ones to compare your accuracy by the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSk-TqFW3FSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier=LogisticRegression(random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNbVPYme5oSh",
        "colab_type": "text"
      },
      "source": [
        "**You can't udrestand the code above?**  \n",
        " you can have a look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) or this tutorial [Building A Logistic Regression in Python, Step by Step](https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvltE5S46c2q",
        "colab_type": "text"
      },
      "source": [
        "**4.Train the Model:**  \n",
        "We can train the model with fit function. (I will explain it to you :) )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IryMoNon3HOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "406a88ae-c515-4d39-ac0e-d8a871d46b2c"
      },
      "source": [
        "classifier.fit(x_train,y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOv05BKb64CI",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we’re fitting the model on the training data and trying to predict the test data.   \n",
        "\n",
        "Now the model is ready to make predictions\n",
        "\n",
        "\n",
        "**4.Make predictions:**  \n",
        "Now that we have trained our algorithm, it’s time to make some predictions. To do so, we will use our test data and predict function and see how accurately our algorithm do. To make predictions on the test data, execute the following script:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WNVOZeAoMIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "401d5697-e409-4b55-bc4d-74c717913adc"
      },
      "source": [
        "predictions=classifier.predict(x_test)\n",
        "predictions"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, 2, 0, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 1, 0, 0, 2, 1, 2, 2,\n",
              "       1, 2, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 0,\n",
              "       2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2,\n",
              "       1, 1, 2, 0, 0, 1, 1, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DumF-u-9hcR",
        "colab_type": "text"
      },
      "source": [
        "these predictions can be matched with the expected output to measure the accuracy value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqItGTvQoWLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d92fa43-bde1-49da-a42a-ff1596dab090"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test,predictions))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9733333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HCGrSoz9lxE",
        "colab_type": "text"
      },
      "source": [
        "So the accuracy is 97% which is no bad :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evEEIJzmABKg",
        "colab_type": "text"
      },
      "source": [
        "This is it for this first day, that took me around 2 hours to make this document but I feel I undrestand more classification and Logistic Regression.\n",
        "Looking forward to practice tomorrow :)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fywu7rHnAUMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
